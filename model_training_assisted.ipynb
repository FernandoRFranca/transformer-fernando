{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep 1.: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multiplicação com math.sqrt(d_model) pois Positional Encoder tem valores iniciais entre -1 e 1 devido a sin e cos.\n",
    "        # Essa multiplicação escala os valores da inicialização do nn.Embedding para próximo da escala do Positional Encoder.\n",
    "        # Inicialização do nn.Embedding é normal com média 0 e standard deviation embedding_dim ** -0.5\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep 2.: Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros((max_seq_length, d_model))\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.: Attention Mechanism Layer (MultiHeadAttention Layer) + Feed Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bias=False explanation**\n",
    "\n",
    "For certain types of layers, such as transformers and convolutional layers, including a bias term is unnecessary and adds unnecessary overhead to the model.\n",
    "\n",
    "The reason for this is that these layers are typically followed by a normalization layer, such as Batch Normalization or Layer Normalization. These normalization layers center the data at mean=0 (and std=1), effectively removing any bias.\n",
    "\n",
    "Therefore, it is common practice to omit the bias term in transformers and convolutional layers that are preceded by a normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # Entra x com shape (batch_size, seq_length, d_model)\n",
    "        seq_length = x.size(1)\n",
    "        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        # Sai y com shape (batch_size, num_heads, seq_length, head_dim)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def compute_attention(self, query, key, value, mask=None):\n",
    "        # Shape de query, key, value (batch_size, num_heads, seq_length, head_dim)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_weights = F.softmax(scores, dim=-1) # dim -1 significa softmax computada ao longo da dimensão head_dim, que é um chunk de embedding.\n",
    "        return torch.matmul(attention_weights, value)\n",
    "    \n",
    "    def combine_heads(self, x, batch_size):\n",
    "        seq_length = x.size(2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x.reshape(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        query = self.split_heads(self.query_linear(query), batch_size)\n",
    "        key = self.split_heads(self.key_linear(key), batch_size)\n",
    "        value = self.split_heads(self.value_linear(value), batch_size)\n",
    "        \n",
    "        attention_weights = self.compute_attention(query, key, value, mask)\n",
    "        output = self.combine_heads(attention_weights, batch_size)\n",
    "        return self.output_linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.: Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask=src_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.positional_encoder = PositionalEncoding(d_model=d_model, max_seq_length=max_seq_length)\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [\n",
    "                EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(n_layers) # noqa E501\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoder(x)\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, src_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, d_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier_nn = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.classifier_nn(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 256\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.2\n",
    "seq_length = 256\n",
    "num_classes = 2\n",
    "\n",
    "transformer_encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, seq_length)\n",
    "classifier = ClassifierHead(d_model, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.: Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1, seq_length, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = (1 - torch.triu(\n",
    "  torch.ones(1, seq_length, seq_length), diagonal=1)\n",
    ").bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask)\n",
    "        x = self.fc(x)\n",
    "        # Log de probabilidades para computação mais rápida e maior estabilidade com probas perto de 0.\n",
    "        # Mapeia [0, 1] para (-inf, 0]\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[457, 812, 385, 732, 773, 206, 769, 487,  73, 416, 620, 975, 457,  78,\n",
       "         520, 937, 527, 399,  70, 748, 889, 848, 751, 639, 854, 194, 349, 856,\n",
       "         844, 445, 280, 960, 463, 209, 295, 898, 939, 587, 718, 145, 989, 267,\n",
       "         336, 619, 852, 244, 960, 150, 805, 105, 525, 132, 372, 743,  17, 806,\n",
       "         763, 611, 564, 843, 467, 848, 446, 490, 723, 537,  75, 268, 798, 338,\n",
       "         127, 565,  60, 117, 784, 717, 671, 817,  85, 455, 739, 973, 626, 364,\n",
       "         409,  51, 529, 233, 451,  40, 893, 658, 723, 679, 570, 482, 972, 385,\n",
       "         579, 488, 793, 486, 748, 272, 464, 830, 336, 486, 717, 297, 982, 315,\n",
       "         711,  63, 848, 434, 873, 677, 602, 711,  35, 229, 235, 298, 667, 854,\n",
       "         205, 307, 954, 709, 409,  37, 759, 603, 790, 645, 564, 760, 386, 302,\n",
       "         649,  88, 739, 485, 971, 822, 181, 271,  56,  41, 484, 121, 204, 594,\n",
       "         285, 799, 122, 180, 947, 367, 443,  49, 680, 947, 311, 293, 821, 353,\n",
       "         910, 516,  30, 976, 578, 951, 893, 630, 152, 224, 969, 471, 535, 733,\n",
       "         917, 537, 819, 991,  50, 379,  82, 288, 947, 537, 443, 860, 824, 163,\n",
       "         186,  24,  25, 305, 933, 679, 262, 396, 283, 631, 757, 988, 243, 927,\n",
       "         490,  13, 970, 133, 168, 656, 427,  21, 613, 174, 517, 937, 415, 756,\n",
       "         932, 317, 631, 602, 193,  83, 964, 717,  66,  89, 124, 347, 486, 154,\n",
       "         707, 586, 652, 177, 947, 285, 828, 449, 424, 348, 169, 260, 632, 820,\n",
       "         561, 271, 767, 496]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "batch_size = 1\n",
    "vocab_size = 1000\n",
    "torch.randint(low=0, high=vocab_size, size=(batch_size, max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 256\n",
    "batch_size = 2\n",
    "vocab_size = 1000\n",
    "input_tokens = torch.randint(low=0, high=vocab_size, size=(batch_size, max_seq_length))\n",
    "\n",
    "transformer_decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)   \n",
    "output = transformer_decoder(input_tokens, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[536, 662, 181, 601, 254, 640, 329, 121, 629, 260, 467, 115, 594, 491,\n",
      "         408, 209, 767, 377, 456, 882, 142, 285, 964,  83, 397,  49, 952, 613,\n",
      "         504, 180, 520, 379, 423, 514, 757, 532, 536, 502,  28, 246, 227, 892,\n",
      "         546, 599, 337, 421, 465, 642, 221, 824, 736, 993, 998, 654, 129, 671,\n",
      "         564, 592, 771, 725, 286, 123, 752, 981,  57, 759, 877, 294, 849, 181,\n",
      "         504,  37, 602, 908, 551,  22, 673, 252, 926, 666, 565, 718,  58, 336,\n",
      "         277, 128,  16, 512,  36, 834, 249, 214, 447, 635, 730, 554, 899, 771,\n",
      "         716, 454, 342, 339, 139, 487, 701, 404, 654, 829, 601, 625, 160, 405,\n",
      "         944, 543, 269, 179,  30, 804,  45, 379, 292, 757, 754, 300, 326, 147,\n",
      "         628,  50, 274, 639,  63, 903, 992, 497, 930, 633, 752, 313, 472, 920,\n",
      "         925, 608, 992, 769,  82, 346, 575, 698, 722, 115, 695, 576,  18, 124,\n",
      "         818, 822, 352, 402, 769, 722, 833, 485, 409, 273, 950,  14, 487,  80,\n",
      "         710, 975, 445, 849, 970, 433, 288, 849, 232,  25,  33, 395, 517,  31,\n",
      "         420, 497, 128, 681, 284, 274, 977, 904,  29, 744, 101, 773,  68, 736,\n",
      "         867, 110, 208, 801, 431, 414, 899, 522, 661, 396, 725, 310, 221,  79,\n",
      "         301, 156, 496, 554, 942, 663, 515, 802, 845,   6, 621, 412, 181, 907,\n",
      "          44, 963, 446, 746, 588, 913, 405, 636,  81, 398, 866, 367, 486, 161,\n",
      "         713, 326, 341, 868, 361, 486, 741, 527, 600, 867, 729,  28, 405, 438,\n",
      "          94, 979, 964,  32],\n",
      "        [ 11, 182, 777, 994, 759, 305, 645, 769, 253, 437, 422, 989, 942, 810,\n",
      "         826, 816, 309, 308, 171, 122,  17,  40, 702,   2, 131, 445, 321, 449,\n",
      "         803, 173,  58, 561, 578, 669, 776, 461, 357, 302, 949, 313, 313, 733,\n",
      "         507,  34, 142, 797,  59,  45, 915, 164, 851, 854, 279, 160, 906, 402,\n",
      "         855, 253, 790, 501, 859, 623, 127, 885, 266, 759,  49,  68, 635, 293,\n",
      "          14, 438, 463, 330, 973, 869, 836, 914, 236, 639, 258, 473, 651, 240,\n",
      "         415, 902, 816, 753, 468, 436, 496, 826, 459,  79, 650, 871, 427, 991,\n",
      "         359, 454, 298, 256, 406,  43, 383, 603, 113, 973, 865, 955, 456, 589,\n",
      "         497, 912,  67, 910, 629, 519, 431, 102, 170, 376, 681, 959, 751, 639,\n",
      "         628, 680,   5, 347, 497, 914, 330, 310, 464, 994,  90, 604, 546, 372,\n",
      "         775, 312, 194, 162, 530, 383, 672, 101, 350, 681, 107, 381, 202, 787,\n",
      "          82, 990, 636, 557, 513, 464, 269, 751, 579, 208, 576, 685, 629, 454,\n",
      "         435, 898, 335, 129, 192, 227, 112, 353, 125, 324, 468, 210, 373, 871,\n",
      "         393, 871, 941, 897, 619, 679, 639, 847,  78, 445, 918, 479, 919, 368,\n",
      "         386, 872, 955, 688, 241, 223, 631, 965, 705, 875, 224, 295, 893, 419,\n",
      "         272, 119, 816,  29, 339, 934, 362, 915, 491, 889, 807, 887, 396, 724,\n",
      "         428, 991, 235, 594, 550, 559,  17, 919, 841, 143, 607, 764, 281,  26,\n",
      "         907, 764, 822, 811, 368,  66, 527, 642, 930, 915,  98, 493, 318, 317,\n",
      "         396, 242, 278, 938]])\n"
     ]
    }
   ],
   "source": [
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-6.4395, -6.9373, -7.8817,  ..., -7.6871, -6.9264, -6.9265],\n",
      "         [-7.3706, -6.5637, -8.5538,  ..., -8.2631, -6.3927, -6.7559],\n",
      "         [-6.8448, -7.1833, -7.7301,  ..., -7.5778, -7.2273, -5.6265],\n",
      "         ...,\n",
      "         [-8.1037, -7.1378, -6.7672,  ..., -7.9400, -6.4561, -7.3698],\n",
      "         [-7.0581, -6.8538, -7.3437,  ..., -6.4154, -7.7382, -6.6302],\n",
      "         [-7.4199, -6.4425, -8.1437,  ..., -5.8654, -6.9702, -6.9465]],\n",
      "\n",
      "        [[-6.7747, -7.1154, -8.1558,  ..., -7.1334, -7.1462, -7.1406],\n",
      "         [-7.0469, -6.4632, -7.1400,  ..., -6.8733, -7.1143, -7.3796],\n",
      "         [-7.3536, -6.4732, -7.4698,  ..., -7.4088, -6.4714, -7.1459],\n",
      "         ...,\n",
      "         [-7.0343, -7.0456, -7.1654,  ..., -7.0362, -7.5145, -6.4881],\n",
      "         [-7.2127, -6.8117, -6.9803,  ..., -7.0661, -7.0490, -8.3353],\n",
      "         [-6.1795, -7.5397, -7.5181,  ..., -7.4484, -7.6458, -7.4995]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(size=(2, 256, 8, 64)).view((2, 256, 512)) # for debugging reshapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4.: Encoder-decoder Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask, cross_mask):\n",
    "        self_attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(self_attn_output))\n",
    "        cross_attn_output = self.cross_attn(x, y, y, cross_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask, cross_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, y, tgt_mask, cross_mask)\n",
    "        x = self.fc(x)\n",
    "        # Log de probabilidades para computação mais rápida e maior estabilidade com probas perto de 0.\n",
    "        # Mapeia [0, 1] para (-inf, 0]\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "        self.decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "\n",
    "    def forward(self, x, src_mask, tgt_mask, cross_mask):\n",
    "        encoder_output = self.encoder(x, src_mask)\n",
    "        decoder_output = self.decoder(x, encoder_output, tgt_mask, cross_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(sequence, pad_token=0):\n",
    "    # Mask out padding tokens (assumes pad_token is 0)\n",
    "    return (sequence != pad_token).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "# sequence = torch.tensor([2, 6, 30, 120, 0, 0, 0, 0])\n",
    "src_mask = generate_padding_mask(input_tokens)\n",
    "cross_mask = src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-7.2952, -7.7172, -6.4120,  ..., -8.0577, -6.7412, -6.9631],\n",
      "         [-8.0978, -5.6856, -6.9766,  ..., -7.3987, -5.9954, -7.1549],\n",
      "         [-6.8227, -6.9482, -6.8970,  ..., -6.4872, -6.5135, -6.8972],\n",
      "         ...,\n",
      "         [-7.2849, -7.2086, -6.8851,  ..., -8.2023, -7.0849, -7.5703],\n",
      "         [-6.5633, -6.9625, -7.1137,  ..., -7.2809, -6.3619, -6.8622],\n",
      "         [-7.9815, -6.7311, -6.9914,  ..., -7.6957, -5.9318, -7.9336]],\n",
      "\n",
      "        [[-7.9445, -7.5784, -7.1699,  ..., -7.4563, -7.4804, -7.3523],\n",
      "         [-8.1715, -6.8377, -6.5618,  ..., -6.8760, -6.6384, -5.8102],\n",
      "         [-8.4128, -7.2745, -7.4224,  ..., -7.3137, -6.4476, -6.8861],\n",
      "         ...,\n",
      "         [-6.9692, -6.8992, -7.4177,  ..., -7.3548, -7.0166, -6.5395],\n",
      "         [-6.2935, -7.0444, -7.1079,  ..., -7.5451, -6.3904, -7.3940],\n",
      "         [-7.0938, -7.0121, -7.0166,  ..., -7.9626, -6.6922, -8.1125]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([2, 256, 1000])\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "outputs = transformer(input_tokens, src_mask, tgt_mask, cross_mask)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 259 tokens possíveis:\n",
    "# ASCII + <UNK> + <SOS> + <EOS> + <PAD>\n",
    "\n",
    "class TokenizerChar:\n",
    "    def __init__(self):\n",
    "        self.chr_to_idx = {chr(v): v for v in range(1, 257)}\n",
    "        self.chr_to_idx['<SOS>'] = 257\n",
    "        self.chr_to_idx['<EOS>'] = 258\n",
    "        self.chr_to_idx['<PAD>'] = 0\n",
    "        self.chr_to_idx['<UNK>'] = 259\n",
    "\n",
    "        self.idx_to_chr = {v: k for k, v in self.chr_to_idx.items()}\n",
    "\n",
    "        self.vocab_size = len(self.chr_to_idx.keys())\n",
    "\n",
    "    def encode(self, char):\n",
    "        if char in self.chr_to_idx.keys():\n",
    "            return self.chr_to_idx[char]\n",
    "        else:\n",
    "            return 259\n",
    "    \n",
    "    def decode(self, token_idx):\n",
    "        return self.idx_to_chr[token_idx]\n",
    "    \n",
    "    def sos_token(self):\n",
    "        return '<SOS>'\n",
    "    \n",
    "    def sos_token_idx(self):\n",
    "        return self.chr_to_idx['<SOS>']\n",
    "\n",
    "    def eos_token(self):\n",
    "        return '<EOS>'\n",
    "    \n",
    "    def eos_token_idx(self):\n",
    "        return self.chr_to_idx['<EOS>']\n",
    "    \n",
    "    def pad_token(self):\n",
    "        return '<PAD>'\n",
    "    \n",
    "    def pad_token_idx(self):\n",
    "        return self.chr_to_idx['<PAD>']\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725\n"
     ]
    }
   ],
   "source": [
    "with open('dataset_text/dialogs.txt') as file:\n",
    "    print(len(file.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DatasetDialogs(Dataset):\n",
    "    def __init__(self, dataset_path, sentence_length):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.sentence_length = sentence_length\n",
    "        self.tokenizer = TokenizerChar()\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return num_of_sentences\n",
    "    \n",
    "    def get_shape(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return (num_of_sentences, self.sentence_length)\n",
    "\n",
    "    def __getitem__(self, line_idx):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            selected_sentence = dataset.read().split('\\n')[line_idx]\n",
    "            if len(selected_sentence) < self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens.append(self.tokenizer.eos_token_idx())\n",
    "                pad_length = self.sentence_length - len(input_tokens) + 1\n",
    "                pad_tokens = [self.tokenizer.pad_token_idx()] * pad_length\n",
    "                input_tokens += pad_tokens\n",
    "            elif len(selected_sentence) == self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            elif len(selected_sentence) > self.sentence_length:\n",
    "                selected_sentence = selected_sentence[:self.sentence_length]\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            # print(f'{len(input_tokens)} - {self.sentence_length}') # debug only\n",
    "            assert len(input_tokens) == self.sentence_length + 1, f\"Lista de índices de tokens não possui mesmo tamanho que 'sentence_length'! len(input_tokens): {len(input_tokens)} - self.sentence_length: {self.sentence_length}\"\n",
    "            try:\n",
    "                x = torch.tensor(input_tokens[:-1])\n",
    "                y = torch.tensor(input_tokens[1:])\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "                print(f\"Input tokens: {input_tokens}\")\n",
    "                raise e\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDialogs('dataset_text/dialogs.txt', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([257, 104, 105,  44,  32, 104, 111, 119,  32,  97, 114, 101,  32, 121,\n",
       "         111, 117,  32, 100, 111, 105, 110, 103,  63,   9, 105,  39, 109,  32,\n",
       "         102, 105, 110, 101,  46,  32, 104, 111, 119,  32,  97,  98, 111, 117,\n",
       "         116,  32, 121, 111, 117, 114, 115, 101, 108, 102,  63, 258,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " tensor([104, 105,  44,  32, 104, 111, 119,  32,  97, 114, 101,  32, 121, 111,\n",
       "         117,  32, 100, 111, 105, 110, 103,  63,   9, 105,  39, 109,  32, 102,\n",
       "         105, 110, 101,  46,  32, 104, 111, 119,  32,  97,  98, 111, 117, 116,\n",
       "          32, 121, 111, 117, 114, 115, 101, 108, 102,  63, 258,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting model training...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.86it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.631200737423367\n",
      "Last batch training loss: 3.270343780517578\n",
      "Epoch validation loss: 3.1462790966033936\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.16it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.217517040393971\n",
      "Last batch training loss: 3.2045228481292725\n",
      "Epoch validation loss: 3.1064573923746743\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.02it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.175163295533922\n",
      "Last batch training loss: 3.1233768463134766\n",
      "Epoch validation loss: 3.1050404707590737\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.04it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.082420304969505\n",
      "Last batch training loss: 3.025723934173584\n",
      "Epoch validation loss: 2.9546426932017007\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.11it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.984009283560294\n",
      "Last batch training loss: 2.988713502883911\n",
      "Epoch validation loss: 2.918907403945923\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.08it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.9456180643152305\n",
      "Last batch training loss: 2.936941623687744\n",
      "Epoch validation loss: 2.9018630981445312\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.20it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.928481667130082\n",
      "Last batch training loss: 2.8524909019470215\n",
      "Epoch validation loss: 2.8910324573516846\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.22it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.9222613793832286\n",
      "Last batch training loss: 2.9172606468200684\n",
      "Epoch validation loss: 2.8777031103769937\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.25it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.902684485470807\n",
      "Last batch training loss: 2.928664207458496\n",
      "Epoch validation loss: 2.864769617716471\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.18it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.850275666625411\n",
      "Last batch training loss: 2.8455817699432373\n",
      "Epoch validation loss: 2.7999914487202964\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.14it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.769008486359208\n",
      "Last batch training loss: 2.6587822437286377\n",
      "Epoch validation loss: 2.6993583838144937\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.14it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.6406862205929227\n",
      "Last batch training loss: 2.498523473739624\n",
      "Epoch validation loss: 2.498384952545166\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.06it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.476541245425189\n",
      "Last batch training loss: 2.3914785385131836\n",
      "Epoch validation loss: 2.377758582433065\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.08it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.3826850431936757\n",
      "Last batch training loss: 2.348893642425537\n",
      "Epoch validation loss: 2.3375622431437173\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  6.03it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.309968347902651\n",
      "Last batch training loss: 2.271655797958374\n",
      "Epoch validation loss: 2.2653963565826416\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.99it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.2571882053657815\n",
      "Last batch training loss: 2.281708002090454\n",
      "Epoch validation loss: 2.2151970863342285\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.99it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.2098090295438415\n",
      "Last batch training loss: 2.162015676498413\n",
      "Epoch validation loss: 2.177963892618815\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.94it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.167961261890553\n",
      "Last batch training loss: 2.1280324459075928\n",
      "Epoch validation loss: 2.1476951440175376\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.94it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.1311797477580883\n",
      "Last batch training loss: 2.1202449798583984\n",
      "Epoch validation loss: 2.1128693421681723\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.95it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.101306509088587\n",
      "Last batch training loss: 2.0806212425231934\n",
      "Epoch validation loss: 2.053911566734314\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.99it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.069378066945959\n",
      "Last batch training loss: 2.065927743911743\n",
      "Epoch validation loss: 2.0545667807261148\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.90it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.034712645742628\n",
      "Last batch training loss: 1.9972240924835205\n",
      "Epoch validation loss: 2.015332341194153\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.79it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.0081084260234126\n",
      "Last batch training loss: 2.0452616214752197\n",
      "Epoch validation loss: 2.0050973097483316\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.12it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.9797711416527077\n",
      "Last batch training loss: 1.9808369874954224\n",
      "Epoch validation loss: 2.010214924812317\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.82it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.9528468361607305\n",
      "Last batch training loss: 1.9018155336380005\n",
      "Epoch validation loss: 1.9482027689615886\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.80it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.927673794605114\n",
      "Last batch training loss: 1.9534002542495728\n",
      "Epoch validation loss: 1.923122485478719\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.71it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.895802546430517\n",
      "Last batch training loss: 1.8328042030334473\n",
      "Epoch validation loss: 1.9270611604054768\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.73it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.873426565417537\n",
      "Last batch training loss: 1.9212485551834106\n",
      "Epoch validation loss: 1.8790709177652996\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.65it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.852707478735182\n",
      "Last batch training loss: 1.818827509880066\n",
      "Epoch validation loss: 1.8550440470377605\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.73it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.83295589906198\n",
      "Last batch training loss: 1.8228161334991455\n",
      "Epoch validation loss: 1.8376917441685994\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.64it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8171954464029383\n",
      "Last batch training loss: 1.7663995027542114\n",
      "Epoch validation loss: 1.8179478645324707\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.66it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7952421638700697\n",
      "Last batch training loss: 1.7802155017852783\n",
      "Epoch validation loss: 1.8215490976969402\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7775881599496912\n",
      "Last batch training loss: 1.8237154483795166\n",
      "Epoch validation loss: 1.7881699403127034\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.58it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.759861327983715\n",
      "Last batch training loss: 1.7586067914962769\n",
      "Epoch validation loss: 1.7881935437520344\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.50it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.737604233953688\n",
      "Last batch training loss: 1.7373161315917969\n",
      "Epoch validation loss: 1.782143235206604\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.57it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7194279917964228\n",
      "Last batch training loss: 1.7526527643203735\n",
      "Epoch validation loss: 1.7731731335322063\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.63it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7031026195596766\n",
      "Last batch training loss: 1.6737476587295532\n",
      "Epoch validation loss: 1.7555227677027385\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.57it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.689928999653569\n",
      "Last batch training loss: 1.6390647888183594\n",
      "Epoch validation loss: 1.7617863416671753\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.57it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6756687694125705\n",
      "Last batch training loss: 1.70615816116333\n",
      "Epoch validation loss: 1.7353893518447876\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.59it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6543612921679463\n",
      "Last batch training loss: 1.6276583671569824\n",
      "Epoch validation loss: 1.7260348002115886\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.56it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6444137493769329\n",
      "Last batch training loss: 1.6910130977630615\n",
      "Epoch validation loss: 1.7140486637751262\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.58it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6273349479392722\n",
      "Last batch training loss: 1.563935399055481\n",
      "Epoch validation loss: 1.7223403453826904\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.54it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6165356238683064\n",
      "Last batch training loss: 1.6425926685333252\n",
      "Epoch validation loss: 1.711678147315979\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.50it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6038325671796445\n",
      "Last batch training loss: 1.5557818412780762\n",
      "Epoch validation loss: 1.7050451040267944\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.55it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5910468278107819\n",
      "Last batch training loss: 1.6560511589050293\n",
      "Epoch validation loss: 1.7146590153376262\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.60it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5790089148062247\n",
      "Last batch training loss: 1.6223037242889404\n",
      "Epoch validation loss: 1.688338001569112\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.49it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5682607977478593\n",
      "Last batch training loss: 1.6014686822891235\n",
      "Epoch validation loss: 1.6525832414627075\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.53it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.553159616611622\n",
      "Last batch training loss: 1.6111876964569092\n",
      "Epoch validation loss: 1.64750341574351\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.50it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.544550237832246\n",
      "Last batch training loss: 1.554160475730896\n",
      "Epoch validation loss: 1.696431557337443\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.50it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5303838738688715\n",
      "Last batch training loss: 1.5169649124145508\n",
      "Epoch validation loss: 1.6544324954350789\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.55it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5195457935333252\n",
      "Last batch training loss: 1.5137351751327515\n",
      "Epoch validation loss: 1.6491927703221638\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.31it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5105449314470645\n",
      "Last batch training loss: 1.5221378803253174\n",
      "Epoch validation loss: 1.6753324270248413\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.47it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4994141569844\n",
      "Last batch training loss: 1.5175645351409912\n",
      "Epoch validation loss: 1.638737440109253\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.46it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4879678222868178\n",
      "Last batch training loss: 1.49513578414917\n",
      "Epoch validation loss: 1.6585108041763306\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.45it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.478119479285346\n",
      "Last batch training loss: 1.5074702501296997\n",
      "Epoch validation loss: 1.6279289325078328\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4677707265924524\n",
      "Last batch training loss: 1.4769420623779297\n",
      "Epoch validation loss: 1.6254883607228596\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.32it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4574999544355605\n",
      "Last batch training loss: 1.4607396125793457\n",
      "Epoch validation loss: 1.6360883315404255\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.52it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4490914388939187\n",
      "Last batch training loss: 1.4908528327941895\n",
      "Epoch validation loss: 1.6372916301091511\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.52it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4388559880080047\n",
      "Last batch training loss: 1.4644023180007935\n",
      "Epoch validation loss: 1.620025356610616\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4305531625394468\n",
      "Last batch training loss: 1.4532864093780518\n",
      "Epoch validation loss: 1.610959490140279\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.49it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4227148515206796\n",
      "Last batch training loss: 1.3885654211044312\n",
      "Epoch validation loss: 1.6150290568669636\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.52it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.413178390926785\n",
      "Last batch training loss: 1.413625717163086\n",
      "Epoch validation loss: 1.6164149045944214\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.39it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4018245449772588\n",
      "Last batch training loss: 1.3981595039367676\n",
      "Epoch validation loss: 1.6117057800292969\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.48it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3944140098713063\n",
      "Last batch training loss: 1.3668015003204346\n",
      "Epoch validation loss: 1.6126211086908977\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.45it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3892123169369168\n",
      "Last batch training loss: 1.3807634115219116\n",
      "Epoch validation loss: 1.605349858601888\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.41it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3848288279992562\n",
      "Last batch training loss: 1.3423805236816406\n",
      "Epoch validation loss: 1.6323504050572712\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.43it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3733824447349265\n",
      "Last batch training loss: 1.3335895538330078\n",
      "Epoch validation loss: 1.6177396774291992\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3674358041198165\n",
      "Last batch training loss: 1.3418118953704834\n",
      "Epoch validation loss: 1.6410496632258098\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.356656131920991\n",
      "Last batch training loss: 1.3129456043243408\n",
      "Epoch validation loss: 1.5834746360778809\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.46it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3480860701313726\n",
      "Last batch training loss: 1.3881807327270508\n",
      "Epoch validation loss: 1.6246823867162068\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3405673503875732\n",
      "Last batch training loss: 1.4086859226226807\n",
      "Epoch validation loss: 1.5967312256495159\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.49it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3298241827223036\n",
      "Last batch training loss: 1.3538657426834106\n",
      "Epoch validation loss: 1.5959595441818237\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.43it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.323707898457845\n",
      "Last batch training loss: 1.3019362688064575\n",
      "Epoch validation loss: 1.5884768168131511\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.314359916581048\n",
      "Last batch training loss: 1.3022477626800537\n",
      "Epoch validation loss: 1.5967770020167034\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.41it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3060209265461675\n",
      "Last batch training loss: 1.359614610671997\n",
      "Epoch validation loss: 1.5930280288060505\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.36it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2972608451490049\n",
      "Last batch training loss: 1.2875182628631592\n",
      "Epoch validation loss: 1.5771726369857788\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.41it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2951776186625164\n",
      "Last batch training loss: 1.3188188076019287\n",
      "Epoch validation loss: 1.6046090523401897\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2844246670051858\n",
      "Last batch training loss: 1.2545149326324463\n",
      "Epoch validation loss: 1.5549076000849407\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.36it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2797812400040802\n",
      "Last batch training loss: 1.2759819030761719\n",
      "Epoch validation loss: 1.6080012321472168\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.36it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.272619229775888\n",
      "Last batch training loss: 1.2526865005493164\n",
      "Epoch validation loss: 1.612975279490153\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.46it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2675558107870597\n",
      "Last batch training loss: 1.2637858390808105\n",
      "Epoch validation loss: 1.55881929397583\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.33it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.263860238922967\n",
      "Last batch training loss: 1.2898036241531372\n",
      "Epoch validation loss: 1.5581261316935222\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2565745380189683\n",
      "Last batch training loss: 1.296628475189209\n",
      "Epoch validation loss: 1.5414034128189087\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.48it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.245595106372127\n",
      "Last batch training loss: 1.249220371246338\n",
      "Epoch validation loss: 1.5753037134806316\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.39it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2464852686281558\n",
      "Last batch training loss: 1.2879194021224976\n",
      "Epoch validation loss: 1.5498493512471516\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.29it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2363834425255105\n",
      "Last batch training loss: 1.234053134918213\n",
      "Epoch validation loss: 1.5461691617965698\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.44it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2318586729190968\n",
      "Last batch training loss: 1.2544015645980835\n",
      "Epoch validation loss: 1.5648193359375\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.47it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2208391781206485\n",
      "Last batch training loss: 1.2091922760009766\n",
      "Epoch validation loss: 1.5951104958852131\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.38it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2167167089603566\n",
      "Last batch training loss: 1.1496130228042603\n",
      "Epoch validation loss: 1.5892661809921265\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.35it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.208462746055038\n",
      "Last batch training loss: 1.2461235523223877\n",
      "Epoch validation loss: 1.591265122095744\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.38it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2054061271526195\n",
      "Last batch training loss: 1.1908705234527588\n",
      "Epoch validation loss: 1.575020710627238\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.42it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2009868886735704\n",
      "Last batch training loss: 1.1815342903137207\n",
      "Epoch validation loss: 1.5645435253779094\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.47it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1960563483061615\n",
      "Last batch training loss: 1.1775708198547363\n",
      "Epoch validation loss: 1.5679397980372112\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.38it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1885741419262357\n",
      "Last batch training loss: 1.159967064857483\n",
      "Epoch validation loss: 1.5706898768742878\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.35it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1793474753697712\n",
      "Last batch training loss: 1.1615978479385376\n",
      "Epoch validation loss: 1.6003543138504028\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:04,  5.46it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1711841071093525\n",
      "Last batch training loss: 1.1668510437011719\n",
      "Epoch validation loss: 1.5762832164764404\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.36it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1641585517812658\n",
      "Last batch training loss: 1.162588119506836\n",
      "Epoch validation loss: 1.5604037841161091\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:05,  5.34it/s]                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1556663115819295\n",
      "Last batch training loss: 1.1466517448425293\n",
      "Epoch validation loss: 1.5728081464767456\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 25/26 [00:04<00:00,  5.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(x, tgt_mask\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, vocab_size), y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m---> 47\u001b[0m avg_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# print(f\"Current training loss: {loss.item()}\")\u001b[39;00m\n\u001b[0;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "sequence_length = 50\n",
    "batch_size = 128\n",
    "dataset_train = DatasetDialogs('dataset_text/dialogs_train.txt', sequence_length)\n",
    "dataset_test = DatasetDialogs('dataset_text/dialogs_test.txt', sequence_length)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "vocab_size = dataset_train.tokenizer.get_vocab_size()\n",
    "\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = sequence_length\n",
    "model = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "tgt_mask = (1 - torch.triu(\n",
    "  torch.ones(1, sequence_length, sequence_length), diagonal=1)\n",
    ").bool()\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear)):\n",
    "        init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "n_epochs = 200\n",
    "n_batches = int(dataset_train.__len__() // batch_size)\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader_train, total=n_batches)):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "        # print(f\"Current training loss: {loss.item()}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    torch.save(model.state_dict(), f'model_checkpoints/model_checkpoint_{epoch+1}.pth')\n",
    "\n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Average epoch training loss: {avg_loss}\")\n",
    "    print(f\"Last batch training loss: {loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader_test):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "    \n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Epoch validation loss: {avg_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation / Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_to_length(sequence, sequence_length, pad_token_idx):\n",
    "    \"\"\"\n",
    "    Completa a sequência com tokens de padding até atingir o comprimento desejado.\n",
    "\n",
    "    Args:\n",
    "        sequence (list): Sequência de tokens (índices) a ser completada.\n",
    "        sequence_length (int): Comprimento desejado da sequência.\n",
    "        pad_token_idx (int): Índice do token de padding.\n",
    "\n",
    "    Returns:\n",
    "        list: Sequência completada com tokens de padding.\n",
    "    \"\"\"\n",
    "    if len(sequence) < sequence_length:\n",
    "        # Adiciona tokens de padding no final da sequência\n",
    "        sequence += [pad_token_idx] * (sequence_length - len(sequence))\n",
    "    elif len(sequence) > sequence_length:\n",
    "        # Trunca a sequência se for maior que o comprimento desejado\n",
    "        sequence = sequence[:sequence_length]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(start_text, model, tokenizer, sequence_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza e preenche a sequência\n",
    "    sequence = [tokenizer.sos_token_idx()] + [tokenizer.encode(c) for c in start_text]\n",
    "    sequence = pad_sequence_to_length(sequence, sequence_length, tokenizer.pad_token_idx())\n",
    "    input_tokens = torch.tensor(sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(start_text), sequence_length):\n",
    "            tgt_mask = torch.tril(torch.ones(sequence_length, sequence_length)).to(device).bool()\n",
    "            outputs = model(input_tokens, tgt_mask=tgt_mask)\n",
    "            log_probs = outputs[0, i - 1] / temperature\n",
    "\n",
    "            predicted_token_idx = torch.distributions.Categorical(logits=log_probs).sample().item()\n",
    "\n",
    "            if predicted_token_idx == tokenizer.eos_token_idx():\n",
    "                break\n",
    "\n",
    "            current_text += tokenizer.decode(predicted_token_idx)\n",
    "            input_tokens[0, i] = predicted_token_idx\n",
    "\n",
    "    print('Texto predito:', current_text)\n",
    "    return current_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: hi, how are you  going to do?\ti'm going to change \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hi, how are you  going to do?\\ti'm going to change \""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('hi, how are you ', model=model, tokenizer=dataset.tokenizer, temperature=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
