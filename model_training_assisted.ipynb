{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep 1.: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multiplicação com math.sqrt(d_model) pois Positional Encoder tem valores iniciais entre -1 e 1 devido a sin e cos.\n",
    "        # Essa multiplicação escala os valores da inicialização do nn.Embedding para próximo da escala do Positional Encoder.\n",
    "        # Inicialização do nn.Embedding é normal com média 0 e standard deviation embedding_dim ** -0.5\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep 2.: Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros((max_seq_length, d_model))\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1.: Attention Mechanism Layer (MultiHeadAttention Layer) + Feed Forward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads\n",
    "\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        # Entra x com shape (batch_size, seq_length, d_model)\n",
    "        seq_length = x.size(1)\n",
    "        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        # Sai y com shape (batch_size, num_heads, seq_length, head_dim)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def compute_attention(self, query, key, value, mask=None):\n",
    "        # Shape de query, key, value (batch_size, num_heads, seq_length, head_dim)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        attention_weights = F.softmax(scores, dim=-1) # dim -1 significa softmax computada ao longo da dimensão head_dim, que é um chunk de embedding.\n",
    "        return torch.matmul(attention_weights, value)\n",
    "    \n",
    "    def combine_heads(self, x, batch_size):\n",
    "        seq_length = x.size(2)\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return x.reshape(batch_size, seq_length, self.d_model)\n",
    "    \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        query = self.split_heads(self.query_linear(query), batch_size)\n",
    "        key = self.split_heads(self.key_linear(key), batch_size)\n",
    "        value = self.split_heads(self.value_linear(value), batch_size)\n",
    "        \n",
    "        attention_weights = self.compute_attention(query, key, value, mask)\n",
    "        output = self.combine_heads(attention_weights, batch_size)\n",
    "        return self.output_linear(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2.: Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask=src_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size=vocab_size, d_model=d_model)\n",
    "        self.positional_encoder = PositionalEncoding(d_model=d_model, max_seq_length=max_seq_length)\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [\n",
    "                EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(n_layers) # noqa E501\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoder(x)\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, src_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierHead(nn.Module):\n",
    "    def __init__(self, d_model, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier_nn = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.classifier_nn(x)\n",
    "        return F.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 256\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.2\n",
    "seq_length = 256\n",
    "num_classes = 2\n",
    "\n",
    "transformer_encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, seq_length)\n",
    "classifier = ClassifierHead(d_model, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3.: Transformer Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(1, seq_length, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 1.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = (1 - torch.triu(\n",
    "  torch.ones(1, seq_length, seq_length), diagonal=1)\n",
    ").bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask)\n",
    "        logits = self.fc(x)\n",
    "        # Log de probabilidades para computação mais rápida e maior estabilidade com probas perto de 0.\n",
    "        # Mapeia [0, 1] para (-inf, 0]\n",
    "        return logits # F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[359, 162, 723, 140, 969, 208, 259,  89, 650, 765, 962,  85, 291, 573,\n",
       "         888,  84, 109, 621, 204, 842,  17, 363, 192,  26, 976, 416,  33, 980,\n",
       "         528, 204,  88, 379, 752, 368,  31, 586, 287, 579, 567, 731, 144, 614,\n",
       "         326, 277, 222, 295, 259, 236, 646, 104, 373, 530, 166, 674,  47, 748,\n",
       "         653, 883, 614, 409, 114, 233,   5, 863, 441, 368, 255, 457, 644,  54,\n",
       "         765, 431,  31, 538, 171, 237, 191, 587, 879, 992, 537, 315, 990,  79,\n",
       "         338, 275, 992, 675,  64, 342, 908, 652, 235, 734, 867, 543, 345, 202,\n",
       "         462, 330, 763, 367, 283, 228, 479, 996,  82, 395, 557, 289, 373, 926,\n",
       "         167, 681, 336,   2, 338, 627, 917,  37, 211,  55, 619, 194, 739, 701,\n",
       "         267,  49, 779, 426, 162, 762, 346,  79, 505, 360, 852, 358, 375, 547,\n",
       "         288, 457,  44, 339, 748, 727, 145, 946, 667, 946, 299, 298, 263, 883,\n",
       "          65, 891, 324, 355, 217, 758, 132, 591, 659, 483, 195,  45, 681, 263,\n",
       "         531, 707, 529, 668, 556, 898, 190, 424, 928, 379, 218, 405, 959, 627,\n",
       "         875, 211,  55, 953, 431,  91, 957, 623, 378, 343, 364, 847, 147, 726,\n",
       "         303, 769, 452, 305, 666, 295, 929, 752, 427, 931, 905, 727, 936, 507,\n",
       "         107, 486, 158, 705, 441, 195, 366, 332, 679, 753, 289, 852, 463, 931,\n",
       "         179, 311, 607, 271, 184, 305,  20, 422, 180, 760, 907, 577, 395, 233,\n",
       "         707, 856,   3, 389, 122, 917,  21, 733, 710, 395, 473, 207, 790, 648,\n",
       "         408,   2, 486, 486]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length = 256\n",
    "batch_size = 1\n",
    "vocab_size = 1000\n",
    "torch.randint(low=0, high=vocab_size, size=(batch_size, max_seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 256\n",
    "batch_size = 2\n",
    "vocab_size = 1000\n",
    "input_tokens = torch.randint(low=0, high=vocab_size, size=(batch_size, max_seq_length))\n",
    "\n",
    "transformer_decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)   \n",
    "output = transformer_decoder(input_tokens, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 78,  50,   3, 643, 193, 693, 708, 164, 527, 685, 273, 485, 865, 445,\n",
      "         449, 207,  17, 785, 786, 931, 451, 281, 580, 488, 362, 499, 870, 890,\n",
      "         121, 730, 567, 568, 792, 900, 844,  31, 326, 712, 720, 312, 906, 114,\n",
      "         914,  46, 393, 136, 713, 212, 928, 536, 499, 454, 810, 333, 196, 252,\n",
      "         950, 907, 301, 480, 236, 271, 558, 167, 243, 386, 182, 744, 741, 282,\n",
      "         545, 742, 626, 449, 441, 132, 128, 497, 450, 716, 537, 195, 496, 288,\n",
      "         195, 785, 486, 196, 207,  77, 939, 899, 393, 597, 518,  93, 797,  36,\n",
      "         601, 286, 368,  50, 169, 570,  54, 359, 370, 705, 107, 140,  96, 188,\n",
      "          41, 720, 373, 469, 828, 298, 292, 414, 649, 808, 948, 892, 429, 868,\n",
      "          95, 339, 274,  65, 753, 823, 914, 430, 623, 947, 659, 862, 550, 282,\n",
      "         544, 849, 763, 122, 543, 511, 260, 728, 582,  68,  20,  74, 706, 467,\n",
      "         143, 868,   2,  62, 436, 592, 147,   6, 975, 517, 175, 419, 131, 337,\n",
      "         748, 702, 136, 473, 386, 972, 950, 309,  42, 432, 313, 551,  59, 341,\n",
      "         745, 623, 802, 567, 330, 656, 500, 560, 199, 200, 704, 359,  60, 930,\n",
      "         767, 978, 784, 756, 412, 323, 519, 529,  43, 863, 634, 287, 704, 120,\n",
      "         570, 260,  26, 402, 164, 785, 788, 799,  53, 784, 852,  23,  90, 680,\n",
      "         526, 360, 660, 139, 567, 116, 679, 777, 247, 802, 904, 354,  35, 157,\n",
      "         258, 819, 201,   7, 755, 377, 468, 200, 152,  60, 645, 829, 927, 754,\n",
      "         392, 550, 325, 556],\n",
      "        [ 41, 220, 273, 666, 614, 726, 188, 249, 963, 748, 163, 361, 642, 200,\n",
      "          40, 594, 558, 215, 958, 727, 248, 509, 996, 969, 534, 155, 453,  67,\n",
      "         188,  21,  33, 540, 936, 658, 755, 502, 259, 960, 172, 777,  45, 286,\n",
      "          65, 735, 343, 768,  95, 378, 750,  71, 816,  26, 487, 706, 248, 719,\n",
      "         828, 325, 185, 404, 660, 673, 954, 378, 195, 120, 958, 775, 492, 519,\n",
      "         202,  27, 194, 182, 833, 831, 735, 554, 182, 989, 926, 112, 110, 473,\n",
      "         892, 144, 630, 260, 990, 770, 934,  76, 473, 977, 397, 537,   3,   6,\n",
      "         906, 727, 496, 249, 339, 132, 916, 133, 632, 768, 969, 790, 564, 739,\n",
      "         710, 895, 904, 556, 940, 196, 612, 642, 782, 153, 387, 379, 787, 797,\n",
      "         721, 889, 435, 172, 721, 666, 994, 332, 668,  23, 122, 213, 950, 939,\n",
      "         454, 963, 910, 763, 807, 950, 730, 667, 151, 295, 560, 737, 573, 817,\n",
      "         850, 164, 994, 249, 705, 190, 192, 417,  59, 245, 686, 561, 168, 873,\n",
      "         527, 855, 353, 828, 160, 629, 726, 827,  69, 768, 495, 724, 175, 873,\n",
      "          11, 274, 902, 397, 597, 191, 325,  98, 542, 438, 161, 123, 567, 477,\n",
      "         868, 416, 175, 540, 604,  87, 622, 922, 475, 302, 163, 220, 582, 113,\n",
      "         101, 336, 314, 925, 681, 522, 515, 544, 426, 578, 831, 381, 498, 204,\n",
      "          85, 207, 393, 535, 281, 625, 826, 287, 963, 803, 527,   1, 951,  51,\n",
      "         486, 438,  36, 920, 297, 471, 393, 967, 813, 211, 114,  69, 773, 144,\n",
      "         511,  21, 420, 569]])\n"
     ]
    }
   ],
   "source": [
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4554, -0.1481, -0.0099,  ..., -0.2201, -0.1905, -0.1033],\n",
      "         [ 0.3121, -1.0453, -0.5668,  ...,  0.0268, -0.9447,  0.0488],\n",
      "         [ 0.2442,  0.4744, -0.4564,  ...,  0.4239,  0.6048,  0.1509],\n",
      "         ...,\n",
      "         [-0.2265,  0.7925,  0.2404,  ..., -1.1820,  0.3571,  0.0399],\n",
      "         [ 0.5802,  0.6000,  0.4702,  ..., -1.1512, -0.7085,  0.4183],\n",
      "         [-0.3865,  0.5531, -0.1136,  ...,  0.8278,  0.4734,  1.0359]],\n",
      "\n",
      "        [[-0.4036, -0.3295,  0.0918,  ...,  0.0761,  0.1926, -0.0362],\n",
      "         [-0.6071,  0.3132, -0.1897,  ..., -0.5080,  0.2858,  0.0533],\n",
      "         [-0.5049,  0.8557,  0.3396,  ...,  0.7998,  0.0855,  0.1365],\n",
      "         ...,\n",
      "         [-0.1669, -0.4839,  0.4137,  ...,  0.7798, -0.2559, -0.1794],\n",
      "         [-0.0708,  0.1759, -0.9030,  ...,  0.2859,  0.3821,  0.0327],\n",
      "         [-0.1576, -0.1774,  0.2091,  ...,  0.3869,  0.1064, -0.3301]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.randn(size=(2, 256, 8, 64)).view((2, 256, 512)) # for debugging reshapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4.: Encoder-decoder Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask, cross_mask):\n",
    "        self_attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(self_attn_output))\n",
    "        cross_attn_output = self.cross_attn(x, y, y, cross_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask, cross_mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, y, tgt_mask, cross_mask)\n",
    "        x = self.fc(x)\n",
    "        # Log de probabilidades para computação mais rápida e maior estabilidade com probas perto de 0.\n",
    "        # Mapeia [0, 1] para (-inf, 0]\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "        self.decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "\n",
    "    def forward(self, x, src_mask, tgt_mask, cross_mask):\n",
    "        encoder_output = self.encoder(x, src_mask)\n",
    "        decoder_output = self.decoder(x, encoder_output, tgt_mask, cross_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(sequence, pad_token=0):\n",
    "    # Mask out padding tokens (assumes pad_token is 0)\n",
    "    return (sequence != pad_token).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "# sequence = torch.tensor([2, 6, 30, 120, 0, 0, 0, 0])\n",
    "src_mask = generate_padding_mask(input_tokens)\n",
    "cross_mask = src_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-7.2952, -7.7172, -6.4120,  ..., -8.0577, -6.7412, -6.9631],\n",
      "         [-8.0978, -5.6856, -6.9766,  ..., -7.3987, -5.9954, -7.1549],\n",
      "         [-6.8227, -6.9482, -6.8970,  ..., -6.4872, -6.5135, -6.8972],\n",
      "         ...,\n",
      "         [-7.2849, -7.2086, -6.8851,  ..., -8.2023, -7.0849, -7.5703],\n",
      "         [-6.5633, -6.9625, -7.1137,  ..., -7.2809, -6.3619, -6.8622],\n",
      "         [-7.9815, -6.7311, -6.9914,  ..., -7.6957, -5.9318, -7.9336]],\n",
      "\n",
      "        [[-7.9445, -7.5784, -7.1699,  ..., -7.4563, -7.4804, -7.3523],\n",
      "         [-8.1715, -6.8377, -6.5618,  ..., -6.8760, -6.6384, -5.8102],\n",
      "         [-8.4128, -7.2745, -7.4224,  ..., -7.3137, -6.4476, -6.8861],\n",
      "         ...,\n",
      "         [-6.9692, -6.8992, -7.4177,  ..., -7.3548, -7.0166, -6.5395],\n",
      "         [-6.2935, -7.0444, -7.1079,  ..., -7.5451, -6.3904, -7.3940],\n",
      "         [-7.0938, -7.0121, -7.0166,  ..., -7.9626, -6.6922, -8.1125]]],\n",
      "       grad_fn=<LogSoftmaxBackward0>)\n",
      "torch.Size([2, 256, 1000])\n"
     ]
    }
   ],
   "source": [
    "transformer = Transformer(vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "outputs = transformer(input_tokens, src_mask, tgt_mask, cross_mask)\n",
    "print(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 259 tokens possíveis:\n",
    "# ASCII + <UNK> + <SOS> + <EOS> + <PAD>\n",
    "\n",
    "class TokenizerChar:\n",
    "    def __init__(self):\n",
    "        self.chr_to_idx = {chr(v): v for v in range(1, 257)}\n",
    "        self.chr_to_idx['<SOS>'] = 257\n",
    "        self.chr_to_idx['<EOS>'] = 258\n",
    "        self.chr_to_idx['<PAD>'] = 0\n",
    "        self.chr_to_idx['<UNK>'] = 259\n",
    "\n",
    "        self.idx_to_chr = {v: k for k, v in self.chr_to_idx.items()}\n",
    "\n",
    "        self.vocab_size = len(self.chr_to_idx.keys())\n",
    "\n",
    "    def encode(self, char):\n",
    "        if char in self.chr_to_idx.keys():\n",
    "            return self.chr_to_idx[char]\n",
    "        else:\n",
    "            return 259\n",
    "    \n",
    "    def decode(self, token_idx):\n",
    "        return self.idx_to_chr[token_idx]\n",
    "    \n",
    "    def sos_token(self):\n",
    "        return '<SOS>'\n",
    "    \n",
    "    def sos_token_idx(self):\n",
    "        return self.chr_to_idx['<SOS>']\n",
    "\n",
    "    def eos_token(self):\n",
    "        return '<EOS>'\n",
    "    \n",
    "    def eos_token_idx(self):\n",
    "        return self.chr_to_idx['<EOS>']\n",
    "    \n",
    "    def pad_token(self):\n",
    "        return '<PAD>'\n",
    "    \n",
    "    def pad_token_idx(self):\n",
    "        return self.chr_to_idx['<PAD>']\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3725\n"
     ]
    }
   ],
   "source": [
    "with open('dataset_text/dialogs.txt') as file:\n",
    "    print(len(file.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DatasetDialogs(Dataset):\n",
    "    def __init__(self, dataset_path, sentence_length):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.sentence_length = sentence_length\n",
    "        self.tokenizer = TokenizerChar()\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return num_of_sentences\n",
    "    \n",
    "    def get_shape(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return (num_of_sentences, self.sentence_length)\n",
    "\n",
    "    def __getitem__(self, line_idx):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            selected_sentence = dataset.read().split('\\n')[line_idx]\n",
    "            if len(selected_sentence) < self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens.append(self.tokenizer.eos_token_idx())\n",
    "                pad_length = self.sentence_length - len(input_tokens) + 1\n",
    "                pad_tokens = [self.tokenizer.pad_token_idx()] * pad_length\n",
    "                input_tokens += pad_tokens\n",
    "            elif len(selected_sentence) == self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            elif len(selected_sentence) > self.sentence_length:\n",
    "                selected_sentence = selected_sentence[:self.sentence_length]\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            # print(f'{len(input_tokens)} - {self.sentence_length}') # debug only\n",
    "            assert len(input_tokens) == self.sentence_length + 1, f\"Lista de índices de tokens não possui mesmo tamanho que 'sentence_length'! len(input_tokens): {len(input_tokens)} - self.sentence_length: {self.sentence_length}\"\n",
    "            try:\n",
    "                x = torch.tensor(input_tokens[:-1])\n",
    "                y = torch.tensor(input_tokens[1:])\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "                print(f\"Input tokens: {input_tokens}\")\n",
    "                raise e\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDialogs('dataset_text/dialogs.txt', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([257, 104, 105,  44,  32, 104, 111, 119,  32,  97, 114, 101,  32, 121,\n",
       "         111, 117,  32, 100, 111, 105, 110, 103,  63,   9, 105,  39, 109,  32,\n",
       "         102, 105, 110, 101,  46,  32, 104, 111, 119,  32,  97,  98, 111, 117,\n",
       "         116,  32, 121, 111, 117, 114, 115, 101, 108, 102,  63, 258,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]),\n",
       " tensor([104, 105,  44,  32, 104, 111, 119,  32,  97, 114, 101,  32, 121, 111,\n",
       "         117,  32, 100, 111, 105, 110, 103,  63,   9, 105,  39, 109,  32, 102,\n",
       "         105, 110, 101,  46,  32, 104, 111, 119,  32,  97,  98, 111, 117, 116,\n",
       "          32, 121, 111, 117, 114, 115, 101, 108, 102,  63, 258,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting model training...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.251866808561521\n",
      "Last batch training loss: 3.145986795425415\n",
      "Epoch validation loss: 3.067007899284363\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:14<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.1171553469149864\n",
      "Last batch training loss: 3.0974152088165283\n",
      "Epoch validation loss: 3.0519294500350953\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.0806717471541645\n",
      "Last batch training loss: 3.0185256004333496\n",
      "Epoch validation loss: 2.96907114982605\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.8311039643866995\n",
      "Last batch training loss: 2.5665242671966553\n",
      "Epoch validation loss: 2.554374623298645\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.482934430380848\n",
      "Last batch training loss: 2.382699728012085\n",
      "Epoch validation loss: 2.376488709449768\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.355214990188028\n",
      "Last batch training loss: 2.2573342323303223\n",
      "Epoch validation loss: 2.2929923295974732\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.270636551848082\n",
      "Last batch training loss: 2.3014845848083496\n",
      "Epoch validation loss: 2.20705885887146\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.195249873901082\n",
      "Last batch training loss: 2.226848840713501\n",
      "Epoch validation loss: 2.156653356552124\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.128161200853152\n",
      "Last batch training loss: 2.1957952976226807\n",
      "Epoch validation loss: 2.111274528503418\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.0698700118287703\n",
      "Last batch training loss: 2.0564870834350586\n",
      "Epoch validation loss: 2.0541015625\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.014673773373399\n",
      "Last batch training loss: 2.03955078125\n",
      "Epoch validation loss: 2.0065454125404356\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.9675393672747032\n",
      "Last batch training loss: 2.0010063648223877\n",
      "Epoch validation loss: 1.9909847497940063\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.9318829685728127\n",
      "Last batch training loss: 1.9237276315689087\n",
      "Epoch validation loss: 1.9282773375511169\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8895205816375875\n",
      "Last batch training loss: 1.8973420858383179\n",
      "Epoch validation loss: 1.9031854629516602\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8533958107511574\n",
      "Last batch training loss: 1.820874571800232\n",
      "Epoch validation loss: 1.8847570300102234\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8202093661388503\n",
      "Last batch training loss: 1.8321703672409058\n",
      "Epoch validation loss: 1.8510371446609497\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7874014533568765\n",
      "Last batch training loss: 1.8062423467636108\n",
      "Epoch validation loss: 1.820282793045044\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7613285791094058\n",
      "Last batch training loss: 1.7036370038986206\n",
      "Epoch validation loss: 1.8241514563560486\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7362059221089443\n",
      "Last batch training loss: 1.7391769886016846\n",
      "Epoch validation loss: 1.806203830242157\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7072206301109814\n",
      "Last batch training loss: 1.6881014108657837\n",
      "Epoch validation loss: 1.7744478464126587\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6828452560389153\n",
      "Last batch training loss: 1.758082389831543\n",
      "Epoch validation loss: 1.7688653826713563\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6612236009579953\n",
      "Last batch training loss: 1.6727275848388672\n",
      "Epoch validation loss: 1.7479785323143004\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6375378726798797\n",
      "Last batch training loss: 1.6986958980560303\n",
      "Epoch validation loss: 1.7425859689712524\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.621959065722528\n",
      "Last batch training loss: 1.6411521434783936\n",
      "Epoch validation loss: 1.7306982636451722\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5988906432535046\n",
      "Last batch training loss: 1.6227463483810425\n",
      "Epoch validation loss: 1.7257278919219972\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5746300989222304\n",
      "Last batch training loss: 1.5865010023117065\n",
      "Epoch validation loss: 1.7132383704185485\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5535674941873996\n",
      "Last batch training loss: 1.5394823551177979\n",
      "Epoch validation loss: 1.7039262175559997\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.537041128238785\n",
      "Last batch training loss: 1.5974630117416382\n",
      "Epoch validation loss: 1.690328884124756\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5283951202285624\n",
      "Last batch training loss: 1.458520531654358\n",
      "Epoch validation loss: 1.6743595957756043\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5086469204626352\n",
      "Last batch training loss: 1.4589226245880127\n",
      "Epoch validation loss: 1.675321877002716\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4902234913032746\n",
      "Last batch training loss: 1.4634512662887573\n",
      "Epoch validation loss: 1.6883554935455323\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.477960580977324\n",
      "Last batch training loss: 1.4394700527191162\n",
      "Epoch validation loss: 1.6527459740638732\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.455547853050945\n",
      "Last batch training loss: 1.413841962814331\n",
      "Epoch validation loss: 1.6618195295333862\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.438943726994167\n",
      "Last batch training loss: 1.388890027999878\n",
      "Epoch validation loss: 1.6741887092590333\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4230147109967526\n",
      "Last batch training loss: 1.403852105140686\n",
      "Epoch validation loss: 1.652684998512268\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4066343062391906\n",
      "Last batch training loss: 1.342697262763977\n",
      "Epoch validation loss: 1.649178671836853\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.389585601949246\n",
      "Last batch training loss: 1.4803358316421509\n",
      "Epoch validation loss: 1.6254518628120422\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3755330292978019\n",
      "Last batch training loss: 1.3236342668533325\n",
      "Epoch validation loss: 1.6303140997886658\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3635048142103392\n",
      "Last batch training loss: 1.3215587139129639\n",
      "Epoch validation loss: 1.6374784469604493\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3515681819381\n",
      "Last batch training loss: 1.2559921741485596\n",
      "Epoch validation loss: 1.65574107170105\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3339243726195575\n",
      "Last batch training loss: 1.422647476196289\n",
      "Epoch validation loss: 1.6396844387054443\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3211579512212879\n",
      "Last batch training loss: 1.3035699129104614\n",
      "Epoch validation loss: 1.6542369842529296\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.305188597919785\n",
      "Last batch training loss: 1.337019443511963\n",
      "Epoch validation loss: 1.6395858883857728\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2915287563733966\n",
      "Last batch training loss: 1.291664958000183\n",
      "Epoch validation loss: 1.634751522541046\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2770134065752832\n",
      "Last batch training loss: 1.3442552089691162\n",
      "Epoch validation loss: 1.6456668972969055\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2654094807455474\n",
      "Last batch training loss: 1.372725009918213\n",
      "Epoch validation loss: 1.6311949372291565\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2568734249221944\n",
      "Last batch training loss: 1.229806900024414\n",
      "Epoch validation loss: 1.6474329233169556\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.241687081684576\n",
      "Last batch training loss: 1.2651147842407227\n",
      "Epoch validation loss: 1.636780023574829\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2305150577955157\n",
      "Last batch training loss: 1.2156800031661987\n",
      "Epoch validation loss: 1.6359745740890503\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2168593150432978\n",
      "Last batch training loss: 1.1891847848892212\n",
      "Epoch validation loss: 1.6346149086952209\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "sequence_length = 200\n",
    "batch_size = 32\n",
    "dataset_train = DatasetDialogs('dataset_text/dialogs_train.txt', sequence_length)\n",
    "dataset_test = DatasetDialogs('dataset_text/dialogs_test.txt', sequence_length)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "vocab_size = dataset_train.tokenizer.get_vocab_size()\n",
    "\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = sequence_length\n",
    "model = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "model.to(device)\n",
    "\n",
    "tgt_mask = (1 - torch.triu(\n",
    "  torch.ones(1, sequence_length, sequence_length), diagonal=1)\n",
    ").bool()\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear)):\n",
    "        init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "n_epochs = 50\n",
    "n_batches = int(dataset_train.__len__() // batch_size)\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader_train, total=n_batches)):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.save(model.state_dict(), f'model_checkpoints/model_checkpoint_{epoch+1}.pth')\n",
    "\n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Average epoch training loss: {avg_loss}\")\n",
    "    print(f\"Last batch training loss: {loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader_test):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "    \n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Epoch validation loss: {avg_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation / Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_to_length(sequence, sequence_length, pad_token_idx):\n",
    "    \"\"\"\n",
    "    Completa a sequência com tokens de padding até atingir o comprimento desejado.\n",
    "\n",
    "    Args:\n",
    "        sequence (list): Sequência de tokens (índices) a ser completada.\n",
    "        sequence_length (int): Comprimento desejado da sequência.\n",
    "        pad_token_idx (int): Índice do token de padding.\n",
    "\n",
    "    Returns:\n",
    "        list: Sequência completada com tokens de padding.\n",
    "    \"\"\"\n",
    "    if len(sequence) < sequence_length:\n",
    "        # Adiciona tokens de padding no final da sequência\n",
    "        sequence += [pad_token_idx] * (sequence_length - len(sequence))\n",
    "    elif len(sequence) > sequence_length:\n",
    "        # Trunca a sequência se for maior que o comprimento desejado\n",
    "        sequence = sequence[:sequence_length]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict(start_text, model, tokenizer, sequence_length=200, temperature=1.0):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza e preenche a sequência\n",
    "    sequence = [tokenizer.sos_token_idx()] + [tokenizer.encode(c) for c in start_text]\n",
    "    sequence = pad_sequence_to_length(sequence, sequence_length, tokenizer.pad_token_idx())\n",
    "    input_tokens = torch.tensor(sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(start_text), sequence_length):\n",
    "            tgt_mask = torch.tril(torch.ones(sequence_length, sequence_length)).to(device).bool()\n",
    "            outputs = model(input_tokens, tgt_mask=tgt_mask)\n",
    "            log_probs = outputs[0, i - 1] / temperature\n",
    "\n",
    "            predicted_token_idx = torch.distributions.Categorical(logits=log_probs).sample().item()\n",
    "\n",
    "            if predicted_token_idx == tokenizer.eos_token_idx():\n",
    "                break\n",
    "\n",
    "            current_text += tokenizer.decode(predicted_token_idx)\n",
    "            input_tokens[0, i] = predicted_token_idx\n",
    "\n",
    "    print('Texto predito:', current_text)\n",
    "    return current_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: i am doing fine,  but i don't have every day.\ti'll bet the best a lot of the bad.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i am doing fine,  but i don't have every day.\\ti'll bet the best a lot of the bad.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('i am doing fine,  ', model=model, tokenizer=dataset.tokenizer, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: hello, are you happy? \ti don't know.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hello, are you happy? \\ti don't know.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('hello, are you happy? ', model=model, tokenizer=dataset.tokenizer, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
