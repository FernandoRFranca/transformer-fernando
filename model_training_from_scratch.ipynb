{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33533516",
   "metadata": {},
   "source": [
    "## Transformer From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb5b06",
   "metadata": {},
   "source": [
    "### Transformer Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8fcedb",
   "metadata": {},
   "source": [
    "#### Next Token Prediction Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370ef06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.init as init\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ca23236",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros((max_seq_length, d_model))\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63e7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"Vetor de embedding precisa ser divisivel pelo número de cabeças da camada de atenção!\"\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.d_model, self.num_heads = d_model, num_heads\n",
    "        self.q = nn.Linear(d_model, d_model)\n",
    "        self.k = nn.Linear(d_model, d_model)\n",
    "        self.v = nn.Linear(d_model, d_model)\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, encoder_output=None):\n",
    "        # Entra Q, K, V com dimensão (batch_size, sequence_length, d_model)\n",
    "        # Reshape para (batch_size, sequence_length, num_heads, d_model)\n",
    "        # Reordering para (batch_size, num_heads, sequence_length, d_model)\n",
    "        if encoder_output is None:\n",
    "            x = torch.reshape(x, shape=(x.shape[0], x.shape[1], self.num_heads, self.head_dim)) #.contiguous()\n",
    "            x = x.permute(0, 2, 1, 3)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Modelo ainda não compatível com Encoder.\")\n",
    "        return x\n",
    "\n",
    "    def compute_attention_scores(self, q_linear_out, k_linear_out, v_linear_out, mask=None):\n",
    "        qk_dot_product = torch.matmul(q_linear_out, k_linear_out.transpose(2, 3)) / self.head_dim ** 0.5\n",
    "\n",
    "        if mask is not None:\n",
    "            qk_dot_product = qk_dot_product.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attn_scores = nn.functional.softmax(qk_dot_product, dim=-1)\n",
    "        attn_weighted_v = torch.matmul(attn_scores, v_linear_out)\n",
    "\n",
    "        return attn_weighted_v\n",
    "\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()\n",
    "        return torch.reshape(x, shape=(x.shape[0], x.shape[1], int(x.shape[2] * x.shape[3])))\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        q_linear_out = self.split_heads(self.q(x))\n",
    "        k_linear_out = self.split_heads(self.k(x))\n",
    "        v_linear_out = self.split_heads(self.v(x))\n",
    "        \n",
    "        attn_weighted_v = self.compute_attention_scores(q_linear_out, k_linear_out, v_linear_out, mask=mask)\n",
    "        attn_weighted_v = self.combine_heads(attn_weighted_v)\n",
    "        return self.output_linear(attn_weighted_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b513ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "matrix_1 = torch.rand(1, 8, 512, 10)\n",
    "matrix_2 = torch.rand(1, 8, 512, 10)\n",
    "print(torch.matmul(matrix_1, matrix_2.transpose(-1, -2)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54c4b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardSubLayer(nn.Module):\n",
    "    def __init__(self, d_model, hidden_size):\n",
    "        super().__init__()\n",
    "        self.ff_1 = nn.Linear(d_model, hidden_size)\n",
    "        self.ff_2 = nn.Linear(hidden_size, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.ff_2(self.relu(self.ff_1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591863be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, hidden_size, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.feed_forward = FeedForwardSubLayer(d_model, hidden_size)\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads) # nn.MultiheadAttention()\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.norm_1(x + self.dropout(self.mha(x, mask=tgt_mask)))\n",
    "        x = self.norm_2(x + self.dropout(self.feed_forward(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "350f1b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, max_sequence_length, n_layers, hidden_size, num_heads, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model, padding_idx=0)\n",
    "        self.pe = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [DecoderBlock(d_model, hidden_size, num_heads, dropout) for _ in range(n_layers)]\n",
    "        )\n",
    "        self.output_layer = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, tgt_mask):\n",
    "        x = self.embedding(x) # torch.nn.functional.pad(x, pad=(0, tgt_mask.shape[1] - x.shape[1]))\n",
    "        x = self.pe(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask)\n",
    "        out = self.output_layer(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c574e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 259 tokens possíveis:\n",
    "# ASCII + <UNK> + <SOS> + <EOS> + <PAD>\n",
    "\n",
    "class TokenizerChar:\n",
    "    def __init__(self):\n",
    "        self.chr_to_idx = {chr(v): v for v in range(1, 257)}\n",
    "        self.chr_to_idx['<SOS>'] = 257\n",
    "        self.chr_to_idx['<EOS>'] = 258\n",
    "        self.chr_to_idx['<PAD>'] = 0\n",
    "        self.chr_to_idx['<UNK>'] = 259\n",
    "\n",
    "        self.idx_to_chr = {v: k for k, v in self.chr_to_idx.items()}\n",
    "\n",
    "        self.vocab_size = len(self.chr_to_idx.keys())\n",
    "\n",
    "    def encode(self, char):\n",
    "        if char in self.chr_to_idx.keys():\n",
    "            return self.chr_to_idx[char]\n",
    "        else:\n",
    "            return 259\n",
    "    \n",
    "    def decode(self, token_idx):\n",
    "        return self.idx_to_chr[token_idx]\n",
    "    \n",
    "    def sos_token(self):\n",
    "        return '<SOS>'\n",
    "    \n",
    "    def sos_token_idx(self):\n",
    "        return self.chr_to_idx['<SOS>']\n",
    "\n",
    "    def eos_token(self):\n",
    "        return '<EOS>'\n",
    "    \n",
    "    def eos_token_idx(self):\n",
    "        return self.chr_to_idx['<EOS>']\n",
    "    \n",
    "    def pad_token(self):\n",
    "        return '<PAD>'\n",
    "    \n",
    "    def pad_token_idx(self):\n",
    "        return self.chr_to_idx['<PAD>']\n",
    "    \n",
    "    def get_vocab_size(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a67c0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class DatasetDialogs(Dataset):\n",
    "    def __init__(self, dataset_path, sentence_length):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.sentence_length = sentence_length\n",
    "        self.tokenizer = TokenizerChar()\n",
    "\n",
    "    def __len__(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return num_of_sentences\n",
    "    \n",
    "    def get_shape(self):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            num_of_sentences = len(dataset.read().split('\\n'))\n",
    "        return (num_of_sentences, self.sentence_length)\n",
    "\n",
    "    def __getitem__(self, line_idx):\n",
    "        with open(self.dataset_path, 'r') as dataset:\n",
    "            selected_sentence = dataset.read().split('\\n')[line_idx]\n",
    "            if len(selected_sentence) < self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens.append(self.tokenizer.eos_token_idx())\n",
    "                pad_length = self.sentence_length - len(input_tokens) + 1\n",
    "                pad_tokens = [self.tokenizer.pad_token_idx()] * pad_length\n",
    "                input_tokens += pad_tokens\n",
    "            elif len(selected_sentence) == self.sentence_length:\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            elif len(selected_sentence) > self.sentence_length:\n",
    "                selected_sentence = selected_sentence[:self.sentence_length]\n",
    "                input_tokens = [self.tokenizer.sos_token_idx()] + [self.tokenizer.encode(char) for char in selected_sentence]\n",
    "                input_tokens[-1] = self.tokenizer.eos_token_idx()\n",
    "            # print(f'{len(input_tokens)} - {self.sentence_length}') # debug only\n",
    "            assert len(input_tokens) == self.sentence_length + 1, f\"Lista de índices de tokens não possui mesmo tamanho que 'sentence_length'! len(input_tokens): {len(input_tokens)} - self.sentence_length: {self.sentence_length}\"\n",
    "            try:\n",
    "                x = torch.tensor(input_tokens[:-1])\n",
    "                y = torch.tensor(input_tokens[1:])\n",
    "            except RuntimeError as e:\n",
    "                print(e)\n",
    "                print(f\"Input tokens: {input_tokens}\")\n",
    "                raise e\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21c8e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Starting model training...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:08<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.2458659711285174\n",
      "Last batch training loss: 3.150761604309082\n",
      "Epoch validation loss: 3.0379201650619505\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.088669195353428\n",
      "Last batch training loss: 3.1086926460266113\n",
      "Epoch validation loss: 3.025111770629883\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.0608464134073703\n",
      "Last batch training loss: 3.0924878120422363\n",
      "Epoch validation loss: 2.996799182891846\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.0424999388578895\n",
      "Last batch training loss: 3.0851898193359375\n",
      "Epoch validation loss: 2.973800849914551\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 3.0222182184736304\n",
      "Last batch training loss: 3.0729527473449707\n",
      "Epoch validation loss: 2.970201849937439\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.932748362282726\n",
      "Last batch training loss: 2.852943181991577\n",
      "Epoch validation loss: 2.7321972370147707\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.666991068938068\n",
      "Last batch training loss: 2.6629786491394043\n",
      "Epoch validation loss: 2.5363375902175904\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.512644720968799\n",
      "Last batch training loss: 2.5197994709014893\n",
      "Epoch validation loss: 2.4078354120254515\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.3865823322367445\n",
      "Last batch training loss: 2.471691370010376\n",
      "Epoch validation loss: 2.319689416885376\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.3129742680308976\n",
      "Last batch training loss: 2.3988847732543945\n",
      "Epoch validation loss: 2.2517327070236206\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.252376291239373\n",
      "Last batch training loss: 2.3383140563964844\n",
      "Epoch validation loss: 2.195799446105957\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.199827740125567\n",
      "Last batch training loss: 2.2986490726470947\n",
      "Epoch validation loss: 2.14315779209137\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.147576248534372\n",
      "Last batch training loss: 2.2622218132019043\n",
      "Epoch validation loss: 2.1139885425567626\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.096043537710315\n",
      "Last batch training loss: 2.2164206504821777\n",
      "Epoch validation loss: 2.0595064997673034\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.0494329249747447\n",
      "Last batch training loss: 2.1771974563598633\n",
      "Epoch validation loss: 2.0188956260681152\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 2.00349745906402\n",
      "Last batch training loss: 2.120504856109619\n",
      "Epoch validation loss: 1.9882047176361084\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.964719863695519\n",
      "Last batch training loss: 2.0716373920440674\n",
      "Epoch validation loss: 1.938533365726471\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.9175561711052869\n",
      "Last batch training loss: 2.0601110458374023\n",
      "Epoch validation loss: 1.9062323093414306\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8793466057732842\n",
      "Last batch training loss: 2.014859199523926\n",
      "Epoch validation loss: 1.8777598142623901\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.845056807883432\n",
      "Last batch training loss: 1.9886656999588013\n",
      "Epoch validation loss: 1.860313594341278\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.8116143317980187\n",
      "Last batch training loss: 1.9381994009017944\n",
      "Epoch validation loss: 1.8316502690315246\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.784659465896749\n",
      "Last batch training loss: 1.9564028978347778\n",
      "Epoch validation loss: 1.944465208053589\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7664202930771302\n",
      "Last batch training loss: 1.8975753784179688\n",
      "Epoch validation loss: 1.7936704635620118\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7267583441511494\n",
      "Last batch training loss: 1.8565219640731812\n",
      "Epoch validation loss: 1.7711947441101075\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.7010868598367566\n",
      "Last batch training loss: 1.847628116607666\n",
      "Epoch validation loss: 1.7567464351654052\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6789818155431302\n",
      "Last batch training loss: 1.8206658363342285\n",
      "Epoch validation loss: 1.7410956263542174\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6565852688851757\n",
      "Last batch training loss: 1.808974027633667\n",
      "Epoch validation loss: 1.729894745349884\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6319976410019064\n",
      "Last batch training loss: 1.7555654048919678\n",
      "Epoch validation loss: 1.7009750366210938\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.6091624509508364\n",
      "Last batch training loss: 1.7583696842193604\n",
      "Epoch validation loss: 1.6934565424919128\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5874448557880436\n",
      "Last batch training loss: 1.735521674156189\n",
      "Epoch validation loss: 1.6804898381233215\n",
      "Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5665514992776317\n",
      "Last batch training loss: 1.6902135610580444\n",
      "Epoch validation loss: 1.6643911480903626\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5462976304170126\n",
      "Last batch training loss: 1.6780424118041992\n",
      "Epoch validation loss: 1.6749812364578247\n",
      "Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5285231354080628\n",
      "Last batch training loss: 1.6480828523635864\n",
      "Epoch validation loss: 1.6590741753578186\n",
      "Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.5112976671379303\n",
      "Last batch training loss: 1.62749445438385\n",
      "Epoch validation loss: 1.649367332458496\n",
      "Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4938189515443605\n",
      "Last batch training loss: 1.7022149562835693\n",
      "Epoch validation loss: 1.654877483844757\n",
      "Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4967309604181307\n",
      "Last batch training loss: 1.6345971822738647\n",
      "Epoch validation loss: 1.632383406162262\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4632136030731915\n",
      "Last batch training loss: 1.6077629327774048\n",
      "Epoch validation loss: 1.6326369643211365\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.442929135304745\n",
      "Last batch training loss: 1.548840880393982\n",
      "Epoch validation loss: 1.6244669437408448\n",
      "Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4245066297388522\n",
      "Last batch training loss: 1.5536494255065918\n",
      "Epoch validation loss: 1.6215940356254577\n",
      "Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.4106627000826542\n",
      "Last batch training loss: 1.5440913438796997\n",
      "Epoch validation loss: 1.6096951007843017\n",
      "Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3932047057374615\n",
      "Last batch training loss: 1.5212568044662476\n",
      "Epoch validation loss: 1.60868399143219\n",
      "Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.37683048649369\n",
      "Last batch training loss: 1.5147464275360107\n",
      "Epoch validation loss: 1.6037568926811219\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3612065448939243\n",
      "Last batch training loss: 1.5233310461044312\n",
      "Epoch validation loss: 1.5925783514976501\n",
      "Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3464526188707797\n",
      "Last batch training loss: 1.4708175659179688\n",
      "Epoch validation loss: 1.5972877144813538\n",
      "Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3358519205423158\n",
      "Last batch training loss: 1.4717708826065063\n",
      "Epoch validation loss: 1.5900057315826417\n",
      "Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.3191616797001562\n",
      "Last batch training loss: 1.4579603672027588\n",
      "Epoch validation loss: 1.586282217502594\n",
      "Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.309049936098473\n",
      "Last batch training loss: 1.4663121700286865\n",
      "Epoch validation loss: 1.5907786011695861\n",
      "Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.296562619298418\n",
      "Last batch training loss: 1.4515047073364258\n",
      "Epoch validation loss: 1.5823691010475158\n",
      "Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2845385993752525\n",
      "Last batch training loss: 1.449761986732483\n",
      "Epoch validation loss: 1.578969132900238\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2715448597881283\n",
      "Last batch training loss: 1.4007861614227295\n",
      "Epoch validation loss: 1.5822626590728759\n",
      "Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2615067685875938\n",
      "Last batch training loss: 1.3797236680984497\n",
      "Epoch validation loss: 1.587569797039032\n",
      "Epoch: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2477462319570167\n",
      "Last batch training loss: 1.3961025476455688\n",
      "Epoch validation loss: 1.5691036820411681\n",
      "Epoch: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2374013400523463\n",
      "Last batch training loss: 1.3613771200180054\n",
      "Epoch validation loss: 1.5745491623878478\n",
      "Epoch: 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.228640384206148\n",
      "Last batch training loss: 1.3515383005142212\n",
      "Epoch validation loss: 1.56990807056427\n",
      "Epoch: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2157401654207818\n",
      "Last batch training loss: 1.3534702062606812\n",
      "Epoch validation loss: 1.5710762739181519\n",
      "Epoch: 56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.2058849802641112\n",
      "Last batch training loss: 1.327820897102356\n",
      "Epoch validation loss: 1.5699811100959777\n",
      "Epoch: 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1964834811531495\n",
      "Last batch training loss: 1.3077750205993652\n",
      "Epoch validation loss: 1.5718865156173707\n",
      "Epoch: 58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1847823256644132\n",
      "Last batch training loss: 1.3305028676986694\n",
      "Epoch validation loss: 1.5733693838119507\n",
      "Epoch: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.174315342836291\n",
      "Last batch training loss: 1.325385332107544\n",
      "Epoch validation loss: 1.5941571116447448\n",
      "Epoch: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.16554704447773\n",
      "Last batch training loss: 1.2949358224868774\n",
      "Epoch validation loss: 1.5810581922531128\n",
      "Epoch: 61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1545147366612871\n",
      "Last batch training loss: 1.3013356924057007\n",
      "Epoch validation loss: 1.5801969289779663\n",
      "Epoch: 62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1427246064783256\n",
      "Last batch training loss: 1.3038700819015503\n",
      "Epoch validation loss: 1.5873427033424377\n",
      "Epoch: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1345342921319408\n",
      "Last batch training loss: 1.2674890756607056\n",
      "Epoch validation loss: 1.5723849654197692\n",
      "Epoch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1261909069301925\n",
      "Last batch training loss: 1.294823169708252\n",
      "Epoch validation loss: 1.5837682485580444\n",
      "Epoch: 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:32<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.115262067763605\n",
      "Last batch training loss: 1.2534153461456299\n",
      "Epoch validation loss: 1.5940488219261169\n",
      "Epoch: 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:08<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.1089761268312686\n",
      "Last batch training loss: 1.2592666149139404\n",
      "Epoch validation loss: 1.6035747528076172\n",
      "Epoch: 67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0957032380817093\n",
      "Last batch training loss: 1.245103120803833\n",
      "Epoch validation loss: 1.605346941947937\n",
      "Epoch: 68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:08<00:00, 12.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0872199212279274\n",
      "Last batch training loss: 1.22137451171875\n",
      "Epoch validation loss: 1.615861749649048\n",
      "Epoch: 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0785248368699973\n",
      "Last batch training loss: 1.2311725616455078\n",
      "Epoch validation loss: 1.5979690194129943\n",
      "Epoch: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.068748805567483\n",
      "Last batch training loss: 1.1996521949768066\n",
      "Epoch validation loss: 1.6271481394767762\n",
      "Epoch: 71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0677339016834153\n",
      "Last batch training loss: 1.1906386613845825\n",
      "Epoch validation loss: 1.6217171669006347\n",
      "Epoch: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0547696101331265\n",
      "Last batch training loss: 1.1826151609420776\n",
      "Epoch validation loss: 1.6223968505859374\n",
      "Epoch: 73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0432972412243067\n",
      "Last batch training loss: 1.1508007049560547\n",
      "Epoch validation loss: 1.636875605583191\n",
      "Epoch: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.036450216146273\n",
      "Last batch training loss: 1.1800448894500732\n",
      "Epoch validation loss: 1.646957552433014\n",
      "Epoch: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0314067139803806\n",
      "Last batch training loss: 1.1739141941070557\n",
      "Epoch validation loss: 1.6343891382217408\n",
      "Epoch: 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0173688759313566\n",
      "Last batch training loss: 1.1600217819213867\n",
      "Epoch validation loss: 1.6435920476913453\n",
      "Epoch: 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 1.0094965551501123\n",
      "Last batch training loss: 1.1341676712036133\n",
      "Epoch validation loss: 1.6332300305366516\n",
      "Epoch: 78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9997802181778667\n",
      "Last batch training loss: 1.1270945072174072\n",
      "Epoch validation loss: 1.6557953834533692\n",
      "Epoch: 79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.991533123444174\n",
      "Last batch training loss: 1.1401190757751465\n",
      "Epoch validation loss: 1.6463997602462768\n",
      "Epoch: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9850439579687386\n",
      "Last batch training loss: 1.1340643167495728\n",
      "Epoch validation loss: 1.6631471514701843\n",
      "Epoch: 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9739979310570476\n",
      "Last batch training loss: 1.1288819313049316\n",
      "Epoch validation loss: 1.6711835861206055\n",
      "Epoch: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9662019593693386\n",
      "Last batch training loss: 1.1021065711975098\n",
      "Epoch validation loss: 1.66290602684021\n",
      "Epoch: 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9613927936999598\n",
      "Last batch training loss: 1.101820468902588\n",
      "Epoch validation loss: 1.6916552782058716\n",
      "Epoch: 84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9503331641170466\n",
      "Last batch training loss: 1.0719692707061768\n",
      "Epoch validation loss: 1.6885416507720947\n",
      "Epoch: 85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9413766554582899\n",
      "Last batch training loss: 1.0649158954620361\n",
      "Epoch validation loss: 1.697167456150055\n",
      "Epoch: 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9333159723014475\n",
      "Last batch training loss: 1.0621840953826904\n",
      "Epoch validation loss: 1.7126036524772643\n",
      "Epoch: 87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9245340389626049\n",
      "Last batch training loss: 1.0588531494140625\n",
      "Epoch validation loss: 1.7094740986824035\n",
      "Epoch: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9195045505728677\n",
      "Last batch training loss: 1.0685832500457764\n",
      "Epoch validation loss: 1.7194653153419495\n",
      "Epoch: 89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.9098524495820018\n",
      "Last batch training loss: 1.0496901273727417\n",
      "Epoch validation loss: 1.712940263748169\n",
      "Epoch: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.899928160916979\n",
      "Last batch training loss: 1.045318841934204\n",
      "Epoch validation loss: 1.7195160508155822\n",
      "Epoch: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.892315376584775\n",
      "Last batch training loss: 1.047141671180725\n",
      "Epoch validation loss: 1.7188438773155212\n",
      "Epoch: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8866919713599659\n",
      "Last batch training loss: 1.0178881883621216\n",
      "Epoch validation loss: 1.7256455898284913\n",
      "Epoch: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8779502828544545\n",
      "Last batch training loss: 1.0082974433898926\n",
      "Epoch validation loss: 1.7364740133285523\n",
      "Epoch: 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8693443598034226\n",
      "Last batch training loss: 1.0093934535980225\n",
      "Epoch validation loss: 1.749776840209961\n",
      "Epoch: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8668881649168853\n",
      "Last batch training loss: 0.9993721842765808\n",
      "Epoch validation loss: 1.7725111722946167\n",
      "Epoch: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8690439479373325\n",
      "Last batch training loss: 1.0303822755813599\n",
      "Epoch validation loss: 1.7347704410552978\n",
      "Epoch: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.855561314342178\n",
      "Last batch training loss: 0.9780593514442444\n",
      "Epoch validation loss: 1.7509577751159668\n",
      "Epoch: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8498220677687743\n",
      "Last batch training loss: 0.9802083373069763\n",
      "Epoch validation loss: 1.7680776953697204\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8390663249470364\n",
      "Last batch training loss: 0.984528124332428\n",
      "Epoch validation loss: 1.767014217376709\n",
      "Epoch: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8303277876889594\n",
      "Last batch training loss: 0.9499963521957397\n",
      "Epoch validation loss: 1.7654722571372985\n",
      "Epoch: 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8242397024252704\n",
      "Last batch training loss: 0.9591460227966309\n",
      "Epoch validation loss: 1.7953692078590393\n",
      "Epoch: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8196438556519624\n",
      "Last batch training loss: 0.944384753704071\n",
      "Epoch validation loss: 1.81068754196167\n",
      "Epoch: 103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8141950079213793\n",
      "Last batch training loss: 0.9567021131515503\n",
      "Epoch validation loss: 1.8090829849243164\n",
      "Epoch: 104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average epoch training loss: 0.8044288219692551\n",
      "Last batch training loss: 0.9204676151275635\n",
      "Epoch validation loss: 1.812583899497986\n",
      "Epoch: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 62/107 [00:05<00:04, 10.45it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader_train, total\u001b[38;5;241m=\u001b[39mn_batches)):\n\u001b[0;32m     43\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 44\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(x, tgt_mask\u001b[38;5;241m.\u001b[39mto(device))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "sequence_length = 100\n",
    "batch_size = 32\n",
    "dataset_train = DatasetDialogs('dataset_text/dialogs_train.txt', sequence_length)\n",
    "dataset_test = DatasetDialogs('dataset_text/dialogs_test.txt', sequence_length)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "vocab_size = dataset_train.tokenizer.get_vocab_size()\n",
    "\n",
    "d_model = 512\n",
    "num_layers = 6\n",
    "num_heads = 8\n",
    "d_ff = 2048\n",
    "dropout = 0.1\n",
    "max_seq_length = sequence_length\n",
    "# model = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "model = TransformerDecoder(vocab_size, d_model, max_seq_length, num_layers, d_ff, num_heads, dropout=0.1)\n",
    "model.to(device)\n",
    "\n",
    "tgt_mask = (1 - torch.triu(\n",
    "  torch.ones(1, sequence_length, sequence_length), diagonal=1)\n",
    ").bool()\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear)):\n",
    "        init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "        if module.bias is not None:\n",
    "            init.zeros_(module.bias)\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n",
    "n_epochs = 1000\n",
    "n_batches = int(dataset_train.__len__() // batch_size)\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    avg_loss = 0\n",
    "    model.train()\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader_train, total=n_batches)):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    torch.save(model.state_dict(), f'model_checkpoints/model_checkpoint_{epoch+1}.pth')\n",
    "\n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Average epoch training loss: {avg_loss}\")\n",
    "    print(f\"Last batch training loss: {loss}\")\n",
    "\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    for batch_idx, batch in enumerate(dataloader_test):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(x, tgt_mask.to(device))\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), y.view(-1))\n",
    "        avg_loss += loss.item()\n",
    "    \n",
    "    avg_loss /= (batch_idx + 1)\n",
    "    print(f\"Epoch validation loss: {avg_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "206019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tgt_mask(sequence_length, device):\n",
    "    tgt_mask = torch.tril(torch.ones(sequence_length, sequence_length, dtype=torch.bool)).to(device)\n",
    "    return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_fernando(start_text, model, tokenizer, max_sequence_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    sequence = [tokenizer.sos_token_idx()] + [tokenizer.encode(c) for c in start_text]\n",
    "\n",
    "    input_tokens = torch.tensor(sequence, dtype=torch.long).unsqueeze(0).to(device) # acrescenta dimensão batch_size=1\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(len(start_text), max_sequence_length):\n",
    "            outputs = model(input_tokens, tgt_mask=make_tgt_mask(input_tokens.shape[1], device))\n",
    "            log_probs = outputs[0, -1] / temperature\n",
    "\n",
    "            predicted_token_idx = torch.distributions.Categorical(logits=log_probs).sample().item()\n",
    "\n",
    "            if predicted_token_idx == tokenizer.eos_token_idx():\n",
    "                break\n",
    "\n",
    "            current_text += tokenizer.decode(predicted_token_idx)\n",
    "            input_tokens = torch.cat((input_tokens, torch.tensor([[predicted_token_idx]]).to(device)), dim=1)\n",
    "\n",
    "    print('Texto predito:', current_text)\n",
    "    return current_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d6d60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence_to_length(sequence, sequence_length, pad_token_idx):\n",
    "    \"\"\"\n",
    "    Completa a sequência com tokens de padding até atingir o comprimento desejado.\n",
    "\n",
    "    Args:\n",
    "        sequence (list): Sequência de tokens (índices) a ser completada.\n",
    "        sequence_length (int): Comprimento desejado da sequência.\n",
    "        pad_token_idx (int): Índice do token de padding.\n",
    "\n",
    "    Returns:\n",
    "        list: Sequência completada com tokens de padding.\n",
    "    \"\"\"\n",
    "    if len(sequence) < sequence_length:\n",
    "        # Adiciona tokens de padding no final da sequência\n",
    "        sequence += [pad_token_idx] * (sequence_length - len(sequence))\n",
    "    elif len(sequence) > sequence_length:\n",
    "        # Trunca a sequência se for maior que o comprimento desejado\n",
    "        sequence = sequence[:sequence_length]\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_assisted(start_text, model, tokenizer, max_sequence_length=50, temperature=1.0):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Tokeniza e preenche a sequência\n",
    "    sequence = [tokenizer.sos_token_idx()] + [tokenizer.encode(c) for c in start_text]\n",
    "    sequence = pad_sequence_to_length(sequence, sequence_length, tokenizer.pad_token_idx())\n",
    "    input_tokens = torch.tensor(sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "    current_text = start_text\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(start_text), sequence_length):\n",
    "            tgt_mask = torch.tril(torch.ones(sequence_length, sequence_length)).to(device).bool()\n",
    "            outputs = model(input_tokens, tgt_mask=tgt_mask)\n",
    "            log_probs = outputs[0, i - 1] / temperature\n",
    "\n",
    "            predicted_token_idx = torch.distributions.Categorical(logits=log_probs).sample().item()\n",
    "\n",
    "            if predicted_token_idx == tokenizer.eos_token_idx():\n",
    "                break\n",
    "\n",
    "            current_text += tokenizer.decode(predicted_token_idx)\n",
    "            input_tokens[0, i] = predicted_token_idx\n",
    "            # if i == 20:\n",
    "            #     print(input_tokens)\n",
    "\n",
    "    print('Texto predito:', current_text)\n",
    "    return current_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c73145b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDialogs('dataset_text/dialogs.txt', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e6993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: you're kidding.\tno, you don't smell radid anymore.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"you're kidding.\\tno, you don't smell radid anymore.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fernando(\"you're kidding.\tno, \", model=model, tokenizer=dataset.tokenizer, max_sequence_length=50, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: you're kidding.\tno, that's a good idea.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"you're kidding.\\tno, that's a good idea.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_fernando(\"you're kidding.\tno, \", model=model, tokenizer=dataset.tokenizer, max_sequence_length=50, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c6e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: you're kidding.\tno,  why don't you wash?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"you're kidding.\\tno,  why don't you wash?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_assisted(\"you're kidding.\tno, \", model=model, tokenizer=dataset.tokenizer, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08dc889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto predito: i'm doing well. how about you?  i'm going to the movies.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i'm doing well. how about you?  i'm going to the movies.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_assisted(\"i'm doing well. how about you? \", model=model, tokenizer=dataset.tokenizer, temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c1ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
